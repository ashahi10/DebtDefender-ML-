{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CMPUT 466/566: Machine Learning, Assignment 1\n",
    "This notebook allows you to run both Decision Tree and Naive Bayes.  \n",
    "Please use Python 3.10.13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy==1.26.3\n",
    "%pip install matplotlib==3.8.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import timeit\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from decision_tree import *\n",
    "from naive_bayes import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 44\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect Pred 1-D Random, 2 class: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39mallclose(predict_dt(tree, X_2), test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_2\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# Optional TODO: Add your own test cases\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m \u001b[43mtest_dt\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mtest_dt\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m X_1 \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mX_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     15\u001b[0m y_1 \u001b[38;5;241m=\u001b[39m test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my_1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mtrain_X\u001b[49m\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     17\u001b[0m tree \u001b[38;5;241m=\u001b[39m train_dt(X_1,\n\u001b[1;32m     18\u001b[0m                 y_1,\n\u001b[1;32m     19\u001b[0m                 seed,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 num_classes,\n\u001b[1;32m     25\u001b[0m                 debug)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCorrect Pred 1-D Linear Seperable, 2 class: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(np\u001b[38;5;241m.\u001b[39mallclose(predict_dt(tree, X_1), test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred_1\u001b[39m\u001b[38;5;124m'\u001b[39m])))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_X' is not defined"
     ]
    }
   ],
   "source": [
    "def test_dt():\n",
    "    with open('./datasets/test_dt.pkl', 'rb') as f:\n",
    "        test = pickle.load(f)\n",
    "\n",
    "    seed = 0\n",
    "    num_classes = 2\n",
    "    max_depth = 10\n",
    "    min_leaf_data = 10\n",
    "    min_entropy = 1e-3\n",
    "    num_split_retries = 10\n",
    "    debug = False\n",
    "\n",
    "    # 1-D Linear Seperable\n",
    "    X_1 = test['X_1']\n",
    "    y_1 = test['y_1']\n",
    "    print(train_X.shape)\n",
    "    tree = train_dt(X_1,\n",
    "                    y_1,\n",
    "                    seed,\n",
    "                    max_depth,\n",
    "                    min_leaf_data,\n",
    "                    min_entropy,\n",
    "                    num_split_retries,\n",
    "                    num_classes,\n",
    "                    debug)\n",
    "    print('Correct Pred 1-D Linear Seperable, 2 class: {}'.format(np.allclose(predict_dt(tree, X_1), test['pred_1'])))\n",
    "\n",
    "    # 1-D Random, 2 Class\n",
    "    X_2 = test['X_2']\n",
    "    y_2 = test['y_2']\n",
    "    tree = train_dt(X_2,\n",
    "                    y_2,\n",
    "                    seed,\n",
    "                    max_depth,\n",
    "                    min_leaf_data,\n",
    "                    min_entropy,\n",
    "                    num_split_retries,\n",
    "                    num_classes,\n",
    "                    debug)\n",
    "    print('Correct Pred 1-D Random, 2 class: {}'.format(np.allclose(predict_dt(tree, X_2), test['pred_2'])))\n",
    "\n",
    "    # Optional TODO: Add your own test cases\n",
    "\n",
    "test_dt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_nb():\n",
    "    with open('./datasets/test_nb.pkl', 'rb') as f:\n",
    "        gt_data = pickle.load(f)\n",
    "        data = gt_data[\"nb\"]\n",
    "\n",
    "    num_features = gt_data[\"X\"].shape[1]\n",
    "    num_classes = len(np.unique(gt_data[\"y\"]))\n",
    "    params = train_nb(gt_data[\"X\"], gt_data[\"y\"], num_classes)\n",
    "\n",
    "    correct_means = np.allclose(params.means, data[\"means\"])\n",
    "    correct_covariances = np.allclose(params.covariances, data[\"covariances\"])\n",
    "    correct_priors = np.allclose(params.priors, data[\"priors\"])\n",
    "\n",
    "    correct_params = Params(data[\"means\"],\n",
    "                            data[\"covariances\"],\n",
    "                            data[\"priors\"],\n",
    "                            num_features,\n",
    "                            num_classes)\n",
    "    model_probs = predict_nb(correct_params, gt_data[\"X\"])\n",
    "    correct_predictions = np.allclose(model_probs, data[\"predictions\"])\n",
    "\n",
    "    print(f\"Correct Means: {correct_means}\")\n",
    "    print(f\"Correct Covariances: {correct_covariances}\")\n",
    "    print(f\"Correct Priors: {correct_priors}\")\n",
    "    print(f\"Correct Predictions: {correct_predictions}\")\n",
    "\n",
    "    print(\"Details:\")\n",
    "    if not correct_means:\n",
    "        print(\"Expected Mean:\")\n",
    "        print(data[\"means\"])\n",
    "        print(\"Got:\")\n",
    "        print(params.means)\n",
    "\n",
    "    if not correct_covariances:\n",
    "        print(\"Expected Covariances:\")\n",
    "        print(data[\"covariances\"])\n",
    "        print(\"Got:\")\n",
    "        print(params.covariances)\n",
    "\n",
    "    if not correct_priors:\n",
    "        print(\"Expected Priors:\")\n",
    "        print(data[\"priors\"])\n",
    "        print(\"Got:\")\n",
    "        print(params.priors)\n",
    "\n",
    "    if not correct_predictions:\n",
    "        print(\"Expected Predictions:\")\n",
    "        print(data[\"predictions\"])\n",
    "        print(\"Got:\")\n",
    "        print(model_probs)\n",
    "\n",
    "    print(\"=\" * 75)\n",
    "\n",
    "    # Optional TODO: Add your own test cases\n",
    "\n",
    "test_nb()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lending Club"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset_info():\n",
    "    with open(\"./datasets/lending_club.pkl\", \"rb\") as f:\n",
    "        lc_data =  pickle.load(f)\n",
    "\n",
    "    # Train data\n",
    "    train_X = lc_data['train_X']\n",
    "    train_y = lc_data['train_y']\n",
    "    \n",
    "    # Validation data\n",
    "    validation_X = lc_data['validation_X']\n",
    "\n",
    "    num_features = train_X.shape[-1]\n",
    "    num_classes = len(np.unique(train_y))\n",
    "\n",
    "    print(\"Dataset Information =============================\")\n",
    "    print(\"Number of input features: {}, Number of classes: {}\".format(num_features, num_classes))\n",
    "    print(\"Number training points: {}\".format(len(train_X)))\n",
    "    print(\"Number validation points: {}\".format(len(validation_X)))\n",
    "    return num_features, num_classes\n",
    "\n",
    "def accuracy(y, p):\n",
    "    \"\"\" This returns the accuracy of prediction given true labels.\n",
    "\n",
    "    Args:\n",
    "    - y (ndarray (shape: (N,1))): A Nx1 matrix consisting of true labels\n",
    "    - p (ndarray (shape: (N,C))): A NxC matrix consisting N C-dimensional probabilities for each input.\n",
    "    \n",
    "    Output:\n",
    "    - acc (float): Accuracy of predictions compared to true labels\n",
    "    \"\"\"\n",
    "    assert y.shape[0] == p.shape[0], f\"Number of samples must match\"\n",
    "\n",
    "    # Pick indicies that maximize each row\n",
    "    y_pred = np.expand_dims(np.argmax(p, axis=1), axis=1)\n",
    "    acc = sum(y_pred == y) * 100 / y.shape[0]\n",
    "\n",
    "    return acc\n",
    "\n",
    "def print_result(train_accs, val_accs, test_accs):\n",
    "    mean_train = np.mean(train_accs, axis=(-1, -2))\n",
    "    std_train = np.std(train_accs, axis=(-1, -2))\n",
    "\n",
    "    mean_val = np.mean(val_accs, axis=(-1, -2))\n",
    "    std_val = np.std(val_accs, axis=(-1, -2))\n",
    "\n",
    "    print(\"Train accuracy: {}% +/- {}\".format(mean_train, std_train,))\n",
    "    print(\"Validation accuracy: {}% +/- {}\".format(mean_val, std_val,))\n",
    "\n",
    "    mean_test = None\n",
    "    std_test = None\n",
    "    if len(test_accs):\n",
    "        mean_test = np.mean(test_accs, axis=(-1, -2))\n",
    "        std_test = np.std(test_accs, axis=(-1, -2))\n",
    "        print(\"Test accuracy: {}% +/- {}\".format(mean_test, std_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Lending Club Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_lc(train, predict, final_hyperparameters, seed, num_runs):\n",
    "    # Load dataset\n",
    "    with open(\"./datasets/lending_club.pkl\", \"rb\") as f:\n",
    "        lc_data =  pickle.load(f)\n",
    "\n",
    "    # Train data\n",
    "    train_X = lc_data['train_X']\n",
    "    train_y = lc_data['train_y']\n",
    "    \n",
    "    # Validation data\n",
    "    validation_X = lc_data['validation_X']\n",
    "    validation_y = lc_data['validation_y']\n",
    "\n",
    "    # Test data\n",
    "    test_X, test_y = None, None\n",
    "    if final_hyperparameters:\n",
    "        test_X = lc_data['test_X']\n",
    "        test_y = lc_data['test_y']\n",
    "\n",
    "    train_accs = []\n",
    "    validation_accs = []\n",
    "    test_accs = []\n",
    "    train_times = []\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    seeds = rng.randint(0, 2 ** 32 - 1, size=(num_runs,))\n",
    "    for run_seed in seeds:\n",
    "        tic = timeit.default_timer()\n",
    "        params = train(train_X, train_y, seed=run_seed)\n",
    "        toc = timeit.default_timer()\n",
    "        train_times.append(toc - tic)\n",
    "\n",
    "        # Training Accuracy\n",
    "        train_predictions = predict(params, train_X)\n",
    "        train_accs.append(accuracy(train_y, train_predictions))\n",
    "\n",
    "        if validation_X is not None and validation_y is not None:\n",
    "            # Validation Accuracy\n",
    "            validation_predictions = predict(params, validation_X)\n",
    "            validation_accs.append(accuracy(validation_y, validation_predictions))\n",
    "\n",
    "        if test_X is not None and test_y is not None:\n",
    "            # Testing Accuracy\n",
    "            test_predictions = predict(params, test_X)\n",
    "            test_accs.append(accuracy(test_y, test_predictions))\n",
    "\n",
    "    return train_accs, validation_accs, test_accs, train_times, seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features, num_classes = get_dataset_info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot train/validation curves\n",
    "Note: This may take around 6.5 minutes to run, longer with inefficient code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = [1, 2, 4, 8, 16, 20]\n",
    "\n",
    "seed = 42\n",
    "num_runs = 5\n",
    "train_accs = []\n",
    "val_accs = []\n",
    "times_taken = []\n",
    "for max_depth in max_depths:\n",
    "    print(\"=\" * 50)\n",
    "    print(\"max_depth = {}\".format(max_depth))\n",
    "    curr_train_accs, curr_val_accs, _, curr_times_taken, seeds = run_lc(\n",
    "        train=partial(train_dt,\n",
    "                      max_depth=max_depth,\n",
    "                      min_leaf_data=1,\n",
    "                      min_entropy=0.0,\n",
    "                      num_split_retries=num_features,\n",
    "                      debug=False,\n",
    "                      num_classes=num_classes,),\n",
    "        predict=predict_dt,\n",
    "        final_hyperparameters=False,\n",
    "        seed=seed,\n",
    "        num_runs=num_runs,\n",
    "    )\n",
    "    times_taken.append(curr_times_taken)\n",
    "    train_accs.append(curr_train_accs)\n",
    "    val_accs.append(curr_val_accs)\n",
    "    print(\"Seeds: {}\".format(seeds))\n",
    "    print(\"Average train accuracy: {}% +/- {}\".format(np.mean(curr_train_accs), np.std(curr_train_accs)))\n",
    "    print(\"Average validation accuracy: {}% +/- {}\".format(np.mean(curr_val_accs), np.std(curr_val_accs)))\n",
    "    print(\"Total time taken: {}s\".format(np.sum(curr_times_taken)))\n",
    "    print(\"Average time taken: {}s +/- {}\".format(np.mean(curr_times_taken), np.std(curr_times_taken)))\n",
    "    print(\"=\" * 50)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train = np.mean(train_accs, axis=(-1, -2))\n",
    "std_train = np.std(train_accs, axis=(-1, -2))\n",
    "\n",
    "mean_val = np.mean(val_accs, axis=(-1, -2))\n",
    "std_val = np.std(val_accs, axis=(-1, -2))\n",
    "\n",
    "plt.plot(max_depths, mean_train, label=\"Train\")\n",
    "plt.fill_between(max_depths, mean_train - std_train, mean_train + std_train, alpha=0.3)\n",
    "\n",
    "plt.plot(max_depths, mean_val, label=\"Validation\")\n",
    "plt.fill_between(max_depths, mean_val - std_val, mean_val + std_val, alpha=0.3)\n",
    "\n",
    "plt.title(\"Decision Tree Accuracy\")\n",
    "plt.xlabel(\"Maximum Depth\")\n",
    "plt.ylabel(\"Accuracy (%)\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above curve, for which value of `maximum_depth` will you choose? Why?  \n",
    "Enter solution in the block below:\n",
    "```\n",
    "TODO: Answer\n",
    "```\n",
    "\n",
    "Given the above observation, can you find the best hyperparameters that will achieve the best performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: validation set to tune hyperparameters for the Occupancy dataset\n",
    "# For efficiency, consider max_depth <= 10.\n",
    "hyperparameters = {\n",
    "    \"max_depth\": 1,\n",
    "    \"min_leaf_data\": 1,\n",
    "    \"min_entropy\": 0.0,\n",
    "    \"num_split_retries\": num_features,\n",
    "    \"debug\": False,\n",
    "    \"num_classes\": num_classes\n",
    "}\n",
    "\n",
    "# TODO: Set final_hyperparameters to True when best hyperparameters is found\n",
    "train_accs, val_accs, test_accs, _, _ = run_lc(train=partial(train_dt,\n",
    "                                                             **hyperparameters),\n",
    "                                               predict=predict_dt,\n",
    "                                               final_hyperparameters=False,\n",
    "                                               seed=seed,\n",
    "                                               num_runs=num_runs)\n",
    "\n",
    "print_result(train_accs, val_accs, test_accs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc, val_acc, test_acc, _, _ = run_lc(train=partial(train_nb,\n",
    "                                                          num_classes=num_classes),\n",
    "                                            predict=predict_nb,\n",
    "                                            final_hyperparameters=True,\n",
    "                                            seed=seed,\n",
    "                                            num_runs=1)\n",
    "print(\"Train accuracy: {}%, Validation accuracy: {}%, Test accuracy: {}%\".format(train_acc, val_acc, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which model will you choose? Why?  \n",
    "Enter solution in the block below:\n",
    "```\n",
    "TODO: Answer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credit\n",
    "CMPUT 466/566 - Machine Learning, Winter 2024, Assignment 1  \n",
    "B. Chan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
